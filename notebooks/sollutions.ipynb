{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:12.941916Z",
     "iopub.status.busy": "2025-06-08T16:31:12.941723Z",
     "iopub.status.idle": "2025-06-08T16:31:18.332729Z",
     "shell.execute_reply": "2025-06-08T16:31:18.331918Z",
     "shell.execute_reply.started": "2025-06-08T16:31:12.941899Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from IPython.display import FileLink\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from IPython.display import Audio\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.334822Z",
     "iopub.status.busy": "2025-06-08T16:31:18.334049Z",
     "iopub.status.idle": "2025-06-08T16:31:18.338108Z",
     "shell.execute_reply": "2025-06-08T16:31:18.337557Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.334801Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as sg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.339560Z",
     "iopub.status.busy": "2025-06-08T16:31:18.338855Z",
     "iopub.status.idle": "2025-06-08T16:31:18.363374Z",
     "shell.execute_reply": "2025-06-08T16:31:18.362658Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.339538Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_energy(signal, sr, window_size=1024, hop_size=512, freq_range=(300, 3000)):\n",
    "    frames = sg.windows.hann(window_size) * np.array(\n",
    "        [signal[i : i + window_size] for i in range(0, len(signal) - window_size, hop_size)]\n",
    "    )\n",
    "\n",
    "    fft_frames = np.fft.rfft(frames, axis=1)\n",
    "    freqs = np.fft.rfftfreq(window_size, 1/sr)\n",
    "    \n",
    "    amplitude_spectrum = np.abs(fft_frames)\n",
    "\n",
    "    freq_mask = (freqs >= freq_range[0]) & (freqs <= freq_range[1])\n",
    "\n",
    "    energy = np.sum(amplitude_spectrum[:, freq_mask], axis=1)\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.364346Z",
     "iopub.status.busy": "2025-06-08T16:31:18.364110Z",
     "iopub.status.idle": "2025-06-08T16:31:18.509930Z",
     "shell.execute_reply": "2025-06-08T16:31:18.509110Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.364329Z"
    }
   },
   "outputs": [],
   "source": [
    "def threshold_filter(signal, sr, window_size=1024, hop_size=512, freq_range=(300, 3000), threshold=1.0, draw=False, threshold_is_mean=False):\n",
    "    \"\"\"\n",
    "    Пороговый фильтр на основе энергии спектра в заданном диапазоне частот.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    hann_window = sg.windows.hann(window_size)\n",
    "    for i in range(0, len(signal) - window_size, hop_size):\n",
    "        frame = signal[i:i + window_size] * hann_window\n",
    "        frames.append(frame)\n",
    "    frames = np.array(frames)\n",
    "\n",
    "    fft_frames = np.fft.rfft(frames, axis=1)\n",
    "    freqs = np.fft.rfftfreq(window_size, 1/sr)\n",
    "\n",
    "    amplitude_spectrum = np.abs(fft_frames)\n",
    "\n",
    "    freq_mask = (freqs >= freq_range[0]) & (freqs <= freq_range[1])\n",
    "\n",
    "    energy = np.sum(amplitude_spectrum[:, freq_mask], axis=1)\n",
    "\n",
    "    if threshold_is_mean:\n",
    "        threshold = np.mean(energy)\n",
    "\n",
    "    if draw:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(energy, linestyle=\"-\", color=\"b\")\n",
    "        plt.axhline(y=threshold, color='r', linestyle='--', label=\"Порог\")\n",
    "        plt.xlabel(\"Окно\")\n",
    "        plt.ylabel(\"Энергия\")\n",
    "        plt.title(\"График энергии аудио\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    mask = (energy >= threshold).astype(int)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def apply_mask(signal, sr, mask, window_size=1024, hop_size=512, remove_silence=True):\n",
    "    hann_window = sg.windows.hann(window_size)\n",
    "    num_samples = len(signal)\n",
    "    \n",
    "    if remove_silence:\n",
    "        output = np.zeros(num_samples)\n",
    "        norm = np.zeros(num_samples)\n",
    "        index = 0\n",
    "\n",
    "        for m in mask:\n",
    "            if index + window_size > num_samples:\n",
    "                break\n",
    "            if m == 1:\n",
    "                output[index:index + window_size] += signal[index:index + window_size] * hann_window\n",
    "                norm[index:index + window_size] += hann_window\n",
    "            index += hop_size\n",
    "\n",
    "        norm[norm == 0] = 1\n",
    "        return output / norm\n",
    "    else:\n",
    "        filtered_signal = np.zeros_like(signal)\n",
    "        window_sum = np.zeros_like(signal)\n",
    "        index = 0\n",
    "\n",
    "        for i in range(len(mask)):\n",
    "            if index + window_size > len(signal):\n",
    "                break\n",
    "            if mask[i] == 1:\n",
    "                filtered_signal[index:index + window_size] += signal[index:index + window_size] * hann_window\n",
    "                window_sum[index:index + window_size] += hann_window\n",
    "            index += hop_size\n",
    "\n",
    "        window_sum[window_sum == 0] = 1\n",
    "        filtered_signal /= window_sum\n",
    "\n",
    "        return filtered_signal\n",
    "\n",
    "def apply_mask_last(signal, sr, mask, window_size=1024, hop_size=512, remove_silence=True):\n",
    "    \"\"\"\n",
    "    Применяет маску к аудиосигналу, удаляя участки с низкой энергией или оставляя только немаскированные окна.\n",
    "    \n",
    "    Параметры:\n",
    "    - signal: 1D массив, исходный аудиосигнал\n",
    "    - sr: частота дискретизации (Hz)\n",
    "    - mask: список 0 и 1, где 1 — сохранить окно, 0 — убрать\n",
    "    - window_size: размер окна (в сэмплах)\n",
    "    - hop_size: шаг окна (в сэмплах)\n",
    "    - remove_silence: если True, сохраняет только немаскированные окна без пауз\n",
    "\n",
    "    Возвращает:\n",
    "    - filtered_signal: сигнал после фильтрации\n",
    "    \"\"\"\n",
    "    filtered_signal = np.zeros_like(signal) if not remove_silence else []\n",
    "    window_sum = np.zeros_like(signal) if not remove_silence else None\n",
    "    hann_window = sg.windows.hann(window_size)\n",
    "    \n",
    "    index = 0\n",
    "    for i in range(len(mask)):\n",
    "        if index + window_size > len(signal):\n",
    "            break\n",
    "        \n",
    "        if mask[i] == 1:\n",
    "            if remove_silence:\n",
    "                filtered_signal.append(signal[index : index + window_size] * hann_window)\n",
    "            else:\n",
    "                filtered_signal[index : index + window_size] += signal[index : index + window_size] * hann_window\n",
    "                window_sum[index : index + window_size] += hann_window\n",
    "        \n",
    "        index += hop_size\n",
    "    \n",
    "    if remove_silence:\n",
    "        filtered_signal = np.concatenate(filtered_signal) if filtered_signal else np.array([])\n",
    "    else:\n",
    "        window_sum[window_sum == 0] = 1\n",
    "        filtered_signal /= window_sum\n",
    "    \n",
    "    return filtered_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.615155Z",
     "iopub.status.busy": "2025-06-08T16:31:18.614965Z",
     "iopub.status.idle": "2025-06-08T16:31:18.647169Z",
     "shell.execute_reply": "2025-06-08T16:31:18.646714Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.615141Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/lw1-acc/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.654096Z",
     "iopub.status.busy": "2025-06-08T16:31:18.653923Z",
     "iopub.status.idle": "2025-06-08T16:31:18.667539Z",
     "shell.execute_reply": "2025-06-08T16:31:18.666861Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.654083Z"
    }
   },
   "outputs": [],
   "source": [
    "way = '/kaggle/input/lw1-acc/audio_train/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.668505Z",
     "iopub.status.busy": "2025-06-08T16:31:18.668289Z",
     "iopub.status.idle": "2025-06-08T16:31:18.689164Z",
     "shell.execute_reply": "2025-06-08T16:31:18.688467Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.668491Z"
    }
   },
   "outputs": [],
   "source": [
    "df['way'] = way + df['fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.690150Z",
     "iopub.status.busy": "2025-06-08T16:31:18.689854Z",
     "iopub.status.idle": "2025-06-08T16:31:18.707136Z",
     "shell.execute_reply": "2025-06-08T16:31:18.706522Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.690133Z"
    }
   },
   "outputs": [],
   "source": [
    "df['label_id'] = pd.factorize(df['label'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.708240Z",
     "iopub.status.busy": "2025-06-08T16:31:18.708010Z",
     "iopub.status.idle": "2025-06-08T16:31:18.724305Z",
     "shell.execute_reply": "2025-06-08T16:31:18.723817Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.708221Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df['label_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.725282Z",
     "iopub.status.busy": "2025-06-08T16:31:18.725078Z",
     "iopub.status.idle": "2025-06-08T16:31:18.740979Z",
     "shell.execute_reply": "2025-06-08T16:31:18.740308Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.725267Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_labels = df['label'].unique().tolist()\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get threshold (ineffective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.741844Z",
     "iopub.status.busy": "2025-06-08T16:31:18.741597Z",
     "iopub.status.idle": "2025-06-08T16:31:18.755388Z",
     "shell.execute_reply": "2025-06-08T16:31:18.754657Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.741825Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_threshold(path):\n",
    "    signal, sr = sf.read(path)\n",
    "    return np.mean(get_energy(signal, sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.756824Z",
     "iopub.status.busy": "2025-06-08T16:31:18.756171Z",
     "iopub.status.idle": "2025-06-08T16:31:18.770774Z",
     "shell.execute_reply": "2025-06-08T16:31:18.770196Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.756803Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['threshold'] = df['way'].apply(get_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:18.786150Z",
     "iopub.status.busy": "2025-06-08T16:31:18.785994Z",
     "iopub.status.idle": "2025-06-08T16:31:39.563987Z",
     "shell.execute_reply": "2025-06-08T16:31:39.563193Z",
     "shell.execute_reply.started": "2025-06-08T16:31:18.786138Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
    "from transformers import AutoProcessor, ASTModel, ASTFeatureExtractor, AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:39.630097Z",
     "iopub.status.busy": "2025-06-08T16:31:39.629916Z",
     "iopub.status.idle": "2025-06-08T16:31:39.654950Z",
     "shell.execute_reply": "2025-06-08T16:31:39.654224Z",
     "shell.execute_reply.started": "2025-06-08T16:31:39.630083Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.01, random_state=42, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple sollution (ineffective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:39.661735Z",
     "iopub.status.busy": "2025-06-08T16:31:39.661521Z",
     "iopub.status.idle": "2025-06-08T16:31:39.674585Z",
     "shell.execute_reply": "2025-06-08T16:31:39.673885Z",
     "shell.execute_reply.started": "2025-06-08T16:31:39.661721Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_features(data):\n",
    "    features = {'spectr':[], 'mel':[], 'mfcc':[], 'labels':[]}\n",
    "    for i in tqdm(range(len(data))):\n",
    "        info = dict(data.iloc[i])\n",
    "        curr_audio, file_sr = sf.read(info['way'])\n",
    "        n_fft = min(2048, len(curr_audio))\n",
    "        features['spectr'].append(np.abs(np.fft.rfft(curr_audio, n=n_fft))),\n",
    "        features['mel'].append(librosa.feature.melspectrogram(y=curr_audio, sr=file_sr, n_mels=64, n_fft=n_fft))\n",
    "        features['mfcc'].append(librosa.feature.mfcc(y=curr_audio, sr=file_sr, n_mfcc=13))\n",
    "        features['labels'].append(info['label_id'])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add augmentation (ineffective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:39.675514Z",
     "iopub.status.busy": "2025-06-08T16:31:39.675306Z",
     "iopub.status.idle": "2025-06-08T16:31:39.689805Z",
     "shell.execute_reply": "2025-06-08T16:31:39.689180Z",
     "shell.execute_reply.started": "2025-06-08T16:31:39.675498Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_stretch(curr_audio, rate=0.5):\n",
    "    augmented_audio = librosa.effects.time_stretch(curr_audio, rate=rate)\n",
    "    return augmented_audio\n",
    "\n",
    "def get_features2(data):\n",
    "    features = {'spectr':[], 'mel':[], 'mfcc':[], 'labels':[]}\n",
    "    for i in tqdm(range(len(data))):\n",
    "        info = dict(data.iloc[i])\n",
    "        first_audio, file_sr = sf.read(info['way'])\n",
    "        threshold = info['threshold']\n",
    "        mask = threshold_filter(first_audio, file_sr, threshold=threshold)\n",
    "        curr_audio = apply_mask(first_audio, file_sr, mask)\n",
    "        while len(curr_audio) == 0:\n",
    "            threshold -= 2\n",
    "            mask = threshold_filter(first_audio, file_sr, threshold=threshold)\n",
    "            curr_audio = apply_mask(first_audio, file_sr, mask)\n",
    "            curr_audio = apply_mask_last(first_audio, file_sr, mask)\n",
    "            curr_audio = time_stretch(curr_audio)\n",
    "        n_fft = min(2048, len(curr_audio))\n",
    "        features['spectr'].append(np.abs(np.fft.rfft(curr_audio, n=n_fft))),\n",
    "        features['mel'].append(librosa.feature.melspectrogram(y=curr_audio, sr=file_sr, n_mels=16, n_fft=n_fft))\n",
    "        features['mfcc'].append(librosa.feature.mfcc(y=curr_audio, sr=file_sr, n_mfcc=13))\n",
    "        features['labels'].append(info['label_id'])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add pretrain output feature extraction (ineffective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:39.690789Z",
     "iopub.status.busy": "2025-06-08T16:31:39.690503Z",
     "iopub.status.idle": "2025-06-08T16:31:39.708211Z",
     "shell.execute_reply": "2025-06-08T16:31:39.707533Z",
     "shell.execute_reply.started": "2025-06-08T16:31:39.690766Z"
    }
   },
   "outputs": [],
   "source": [
    "# extractor = AutoFeatureExtractor.from_pretrained(\"bookbot/distil-ast-audioset\")\n",
    "# model_extractor = AutoModelForAudioClassification.from_pretrained(\"bookbot/distil-ast-audioset\") \n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model_extractor.to(device)\n",
    "# def get_features3(data):\n",
    "#     features = {'spectr':[], 'mel':[], 'mfcc':[], 'labels':[]}\n",
    "#     for i in tqdm(range(len(data))):\n",
    "#         info = dict(data.iloc[i])\n",
    "#         first_audio, file_sr = sf.read(info['way'])\n",
    "#         inputs = extractor(first_audio, sampling_rate=file_sr, return_tensors=\"pt\")\n",
    "#         with torch.no_grad():\n",
    "#             emb = model_extractor.audio_spectrogram_transformer(**inputs.to(device))['pooler_output'][0].to('cpu')\n",
    "#         features['spectr'].append(emb)\n",
    "#         features['labels'].append(info['label_id'])\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add distill pretrain input feature extraction (less effective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:39.709168Z",
     "iopub.status.busy": "2025-06-08T16:31:39.708936Z",
     "iopub.status.idle": "2025-06-08T16:31:39.723646Z",
     "shell.execute_reply": "2025-06-08T16:31:39.722904Z",
     "shell.execute_reply.started": "2025-06-08T16:31:39.709147Z"
    }
   },
   "outputs": [],
   "source": [
    "# extractor = AutoFeatureExtractor.from_pretrained(\"bookbot/distil-ast-audioset\")\n",
    "# def get_features4(data):\n",
    "#     features = {'spectr':[], 'mel':[], 'mfcc':[], 'labels':[]}\n",
    "#     for i in tqdm(range(len(data))):\n",
    "#         info = dict(data.iloc[i])\n",
    "#         first_audio, file_sr = sf.read(info['way'])\n",
    "#         inputs = extractor(first_audio, sampling_rate=file_sr, return_tensors=\"pt\")\n",
    "#         features['spectr'].append(inputs)\n",
    "#         features['labels'].append(info['label_id'])\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:39.724421Z",
     "iopub.status.busy": "2025-06-08T16:31:39.724248Z",
     "iopub.status.idle": "2025-06-08T16:31:39.740960Z",
     "shell.execute_reply": "2025-06-08T16:31:39.740287Z",
     "shell.execute_reply.started": "2025-06-08T16:31:39.724406Z"
    },
    "scrolled": true
   },
   "source": [
    "## Add large pretrain input extraction (most effective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:39.756106Z",
     "iopub.status.busy": "2025-06-08T16:31:39.755926Z",
     "iopub.status.idle": "2025-06-08T16:31:39.769595Z",
     "shell.execute_reply": "2025-06-08T16:31:39.768856Z",
     "shell.execute_reply.started": "2025-06-08T16:31:39.756092Z"
    }
   },
   "outputs": [],
   "source": [
    "extractor = ASTFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "def get_features5(data):\n",
    "    features = {'spectr':[], 'mel':[], 'mfcc':[], 'labels':[]}\n",
    "    for i in tqdm(range(len(data))):\n",
    "        info = dict(data.iloc[i])\n",
    "        x = librosa.load(info['way'], sr=16000)[0]\n",
    "        x, _ = librosa.effects.trim(x)\n",
    "        x = extractor(x, sampling_rate=16000, return_tensors=\"pt\")[\"input_values\"]\n",
    "        features['spectr'].append(x)\n",
    "        features['labels'].append(info['label_id'])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add large pretrain input extraction (too large for Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:39.742291Z",
     "iopub.status.busy": "2025-06-08T16:31:39.741806Z",
     "iopub.status.idle": "2025-06-08T16:31:39.755240Z",
     "shell.execute_reply": "2025-06-08T16:31:39.754548Z",
     "shell.execute_reply.started": "2025-06-08T16:31:39.742274Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_noise(x, noise_level=0.01):\n",
    "    noise = np.random.randn(len(x))\n",
    "    return x + noise_level * noise\n",
    "\n",
    "def pad_or_trim(x, length=16000):\n",
    "    if len(x) > length:\n",
    "        return x[:length]\n",
    "    else:\n",
    "        return np.pad(x, (0, length - len(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:39.770509Z",
     "iopub.status.busy": "2025-06-08T16:31:39.770328Z",
     "iopub.status.idle": "2025-06-08T16:31:40.710898Z",
     "shell.execute_reply": "2025-06-08T16:31:40.710142Z",
     "shell.execute_reply.started": "2025-06-08T16:31:39.770496Z"
    }
   },
   "outputs": [],
   "source": [
    "extractor = ASTFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "def get_features5(data, p_time_mask=0.5, p_freq_mask=0.5, p_noise=0.5):\n",
    "    time_mask = T.TimeMasking(time_mask_param=80)\n",
    "    freq_mask = T.FrequencyMasking(freq_mask_param=16)\n",
    "    \n",
    "    features = {'spectr': [], 'mel': [], 'mfcc': [], 'labels': []}\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        info = dict(data.iloc[i])\n",
    "        x = librosa.load(info['way'], sr=16000)[0]\n",
    "        xx, _ = librosa.effects.trim(x)\n",
    "\n",
    "        x_orig = extractor(xx, sampling_rate=16000, return_tensors=\"pt\")[\"input_values\"]\n",
    "        features['spectr'].append(x_orig)\n",
    "        features['labels'].append(info['label_id'])\n",
    "\n",
    "        if random.random() < p_time_mask:\n",
    "            x_tm = time_mask(x_orig.clone())  \n",
    "            features['spectr'].append(x_tm)\n",
    "            features['labels'].append(info['label_id'])\n",
    "\n",
    "        if random.random() < p_freq_mask:\n",
    "            x_fm = freq_mask(x_orig.clone())\n",
    "            features['spectr'].append(x_fm)\n",
    "            features['labels'].append(info['label_id'])\n",
    "\n",
    "        if random.random() < p_noise:\n",
    "            x_noisy = add_noise(xx, noise_level=0.01)\n",
    "            x_aug = extractor(x_noisy, sampling_rate=16000, return_tensors=\"pt\")[\"input_values\"]\n",
    "            features['spectr'].append(x_aug)\n",
    "            features['labels'].append(info['label_id'])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:31:40.747163Z",
     "iopub.status.busy": "2025-06-08T16:31:40.746925Z",
     "iopub.status.idle": "2025-06-08T16:34:05.840545Z",
     "shell.execute_reply": "2025-06-08T16:34:05.839936Z",
     "shell.execute_reply.started": "2025-06-08T16:31:40.747148Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = get_features5(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:05.841561Z",
     "iopub.status.busy": "2025-06-08T16:34:05.841341Z",
     "iopub.status.idle": "2025-06-08T16:34:06.363514Z",
     "shell.execute_reply": "2025-06-08T16:34:06.362794Z",
     "shell.execute_reply.started": "2025-06-08T16:34:05.841544Z"
    }
   },
   "outputs": [],
   "source": [
    "test_features = get_features5(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:06.369329Z",
     "iopub.status.busy": "2025-06-08T16:34:06.369138Z",
     "iopub.status.idle": "2025-06-08T16:34:06.384565Z",
     "shell.execute_reply": "2025-06-08T16:34:06.383956Z",
     "shell.execute_reply.started": "2025-06-08T16:34:06.369314Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('train.pkl', 'wb') as f:\n",
    "    pickle.dump(train_features, f)\n",
    "\n",
    "with open('test.pkl', 'wb') as f:\n",
    "    pickle.dump(test_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:06.445691Z",
     "iopub.status.busy": "2025-06-08T16:34:06.445379Z",
     "iopub.status.idle": "2025-06-08T16:34:06.461477Z",
     "shell.execute_reply": "2025-06-08T16:34:06.460976Z",
     "shell.execute_reply.started": "2025-06-08T16:34:06.445672Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_sequence(seq, max_len):\n",
    "    seq = seq.flatten()  # Преобразуем в массив, если это список\n",
    "    if len(seq) < max_len:\n",
    "        return np.pad(seq, (0, max_len - len(seq)), mode='constant')\n",
    "    else:\n",
    "        return seq[:max_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Own data pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.265090Z",
     "iopub.status.busy": "2025-06-08T16:34:08.264610Z",
     "iopub.status.idle": "2025-06-08T16:34:08.280466Z",
     "shell.execute_reply": "2025-06-08T16:34:08.279995Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.265068Z"
    }
   },
   "outputs": [],
   "source": [
    "# max_len = max([spectr.flatten().shape for spectr in train_features['spectr']])[0] \n",
    "# train_features['spectr'] = np.array([pad_sequence(m, max_len) for m in train_features['spectr']], dtype=np.float32)\n",
    "# test_features['spectr'] = np.array([pad_sequence(m, max_len) for m in test_features['spectr']], dtype=np.float32)\n",
    "\n",
    "# max_len = max([mfcc.flatten().shape for mfcc in train_features['mfcc']])[0] \n",
    "# train_features['mfcc'] = np.array([pad_sequence(m, max_len) for m in train_features['mfcc']], dtype=np.float32)\n",
    "# test_features['mfcc'] = np.array([pad_sequence(m, max_len) for m in test_features['mfcc']], dtype=np.float32)\n",
    "\n",
    "# max_len = max([mel.flatten().shape for mel in train_features['mel']])[0] \n",
    "# train_features['mel'] = np.array([pad_sequence(m, max_len) for m in train_features['mel']], dtype=np.float32)\n",
    "# test_features['mel'] = np.array([pad_sequence(m, max_len) for m in test_features['mel']], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preptrain 3.3 - 3.4 pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.260477Z",
     "iopub.status.busy": "2025-06-08T16:34:08.260290Z",
     "iopub.status.idle": "2025-06-08T16:34:08.263859Z",
     "shell.execute_reply": "2025-06-08T16:34:08.263067Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.260464Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_features['spectr'] = np.array([m['input_values'] for m in train_features['spectr']], dtype=np.float32)\n",
    "# test_features['spectr'] = np.array([m['input_values'] for m in test_features['spectr']], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large pretrain pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:06.489669Z",
     "iopub.status.busy": "2025-06-08T16:34:06.489387Z",
     "iopub.status.idle": "2025-06-08T16:34:08.259397Z",
     "shell.execute_reply": "2025-06-08T16:34:08.258638Z",
     "shell.execute_reply.started": "2025-06-08T16:34:06.489638Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features['spectr'] = np.array([m[0] for m in train_features['spectr']], dtype=np.float32)\n",
    "test_features['spectr'] = np.array([m[0] for m in test_features['spectr']], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.281607Z",
     "iopub.status.busy": "2025-06-08T16:34:08.281383Z",
     "iopub.status.idle": "2025-06-08T16:34:08.297133Z",
     "shell.execute_reply": "2025-06-08T16:34:08.296562Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.281592Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(train_features['mfcc']), len(train_features['mel']), len(train_features['spectr']),\n",
    "# len(test_features['mfcc']), len(test_features['mel']), len(test_features['spectr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.298008Z",
     "iopub.status.busy": "2025-06-08T16:34:08.297815Z",
     "iopub.status.idle": "2025-06-08T16:34:08.315753Z",
     "shell.execute_reply": "2025-06-08T16:34:08.315129Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.297986Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def approximate_factors(n):\n",
    "    sqrt_n = int(math.sqrt(n))\n",
    "    \n",
    "    for i in range(sqrt_n, 0, -1):\n",
    "        if n % i == 0:\n",
    "            return (i, n // i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.331261Z",
     "iopub.status.busy": "2025-06-08T16:34:08.330947Z",
     "iopub.status.idle": "2025-06-08T16:34:08.347581Z",
     "shell.execute_reply": "2025-06-08T16:34:08.346945Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.331236Z"
    }
   },
   "outputs": [],
   "source": [
    "class model_register():\n",
    "    def __init__(self, ):\n",
    "        self.batch_size = 10 #128\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.lr = 1e-5\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.results = {}\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def gen_datasets(self, train, test, mode='spectr'):\n",
    "        # self.device = 'cpu'\n",
    "        X_train, X_test, y_train, y_test = train[mode], test[mode], train['labels'], test['labels']\n",
    "        inputs_train = torch.tensor(X_train, dtype=torch.float32)#.to(self.device)\n",
    "        targets_train = torch.tensor([i for i in y_train], dtype=torch.long)\n",
    "        inputs_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "        targets_test = torch.tensor([i for i in y_test], dtype=torch.long)\n",
    "        self.input_dim = inputs_train.shape[1:]\n",
    "        self.input_dim = torch.prod(torch.tensor(model.input_dim))\n",
    "        inputs_train = inputs_train.view(inputs_train.shape[0], self.input_dim)\n",
    "        inputs_test = inputs_test.view(inputs_test.shape[0], self.input_dim)\n",
    "        train = data_utils.TensorDataset(inputs_train.to(self.device), targets_train.to(self.device))\n",
    "        test = data_utils.TensorDataset(inputs_test.to(self.device), targets_test.to(self.device))\n",
    "        self.trainset = torch.utils.data.DataLoader(train, batch_size=self.batch_size, shuffle=True)\n",
    "        self.testset = torch.utils.data.DataLoader(test, batch_size=self.batch_size, shuffle=False)\n",
    "        # self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def get_model(self):\n",
    "        self.model = Classifier(self.input_dim).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    def train(self, epochs=10):\n",
    "        for epoch in range(epochs):\n",
    "                with tqdm(self.trainset, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True) as pbar:\n",
    "                    for X, y in pbar:\n",
    "                        self.optimizer.zero_grad()\n",
    "                        # print(X.shape)\n",
    "                        out = self.model(X.to(self.device))\n",
    "                        out = out.view(-1, out.shape[-1])\n",
    "                        loss = self.loss_function(out, y.to(self.device))\n",
    "                        loss.backward()\n",
    "                        self.optimizer.step()\n",
    "                        pbar.set_postfix(loss=loss.item())\n",
    "                self.scheduler.step()\n",
    "\n",
    "    def test(self, to_print=True):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        targets = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            with tqdm(self.testset, desc=\"Testing\", leave=True) as pbar:\n",
    "                for X, y in pbar:\n",
    "                    X, y = X.to(self.device), y.cpu()\n",
    "    \n",
    "                    output = self.model(X)\n",
    "    \n",
    "                    preds = torch.argmax(output, dim=-1).cpu().numpy()\n",
    "    \n",
    "                    targets.extend(y.numpy())\n",
    "                    predictions.extend(preds)\n",
    "    \n",
    "        f1 = f1_score(targets, predictions, average=\"macro\")\n",
    "\n",
    "        if to_print:\n",
    "            print(f\"F1-score (macro): {f1:.4f}\")\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.348530Z",
     "iopub.status.busy": "2025-06-08T16:34:08.348285Z",
     "iopub.status.idle": "2025-06-08T16:34:08.365410Z",
     "shell.execute_reply": "2025-06-08T16:34:08.364767Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.348508Z"
    }
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, num_layers=4, nheads=8, num_classes=41, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim * 8\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, nhead=nheads, dim_feedforward=hidden_dim * 4, dropout=dropout_rate\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.unsqueeze(0)  \n",
    "\n",
    "        x = self.transformer(x)\n",
    "        x = x.squeeze(0)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        out = self.fc_out(x)  \n",
    "        return out  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.366320Z",
     "iopub.status.busy": "2025-06-08T16:34:08.366075Z",
     "iopub.status.idle": "2025-06-08T16:34:08.384929Z",
     "shell.execute_reply": "2025-06-08T16:34:08.384251Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.366301Z"
    }
   },
   "source": [
    "## Classifier Inception+Residual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.386027Z",
     "iopub.status.busy": "2025-06-08T16:34:08.385717Z",
     "iopub.status.idle": "2025-06-08T16:34:08.403990Z",
     "shell.execute_reply": "2025-06-08T16:34:08.403461Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.386006Z"
    }
   },
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.branch1x1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch5x5_2 = nn.Conv2d(16, 16, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch3x3_2 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1, branch5x5, branch3x3, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        out_channels = out_channels - in_channels\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) < 3:\n",
    "            a, b = approximate_factors(x.shape[-1])\n",
    "            x = x.unsqueeze(1).view(x.shape[0], 1, a, b) \n",
    "        identity = x \n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.relu(out)\n",
    "        out = torch.cat((identity, out), dim=1)\n",
    "        return out\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, batch_size=64, hidden_dim=512, num_layers=4, nheads=8, num_classes=41, dropout_rate=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim * 8\n",
    "\n",
    "        self.res_block1 = ResidualBlock(1, 32)  \n",
    "        self.res_block2 = ResidualBlock(32, 64)\n",
    "        self.res_block3 = ResidualBlock(64, 128)\n",
    "        self.res_block4 = ResidualBlock(128, 256)\n",
    "        self.res_block5 = ResidualBlock(256, 512)\n",
    "\n",
    "        self.inception = InceptionBlock(128)\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim*batch_size, hidden_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, nhead=nheads, dim_feedforward=hidden_dim * 4, dropout=dropout_rate\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        x = self.res_block4(x)\n",
    "        x = self.res_block5(x)\n",
    "\n",
    "        x = self.inception(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.unsqueeze(0) \n",
    "\n",
    "        x = self.transformer(x)\n",
    "        x = x.squeeze(0)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        out = self.fc_out(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.404932Z",
     "iopub.status.busy": "2025-06-08T16:34:08.404679Z",
     "iopub.status.idle": "2025-06-08T16:34:08.425660Z",
     "shell.execute_reply": "2025-06-08T16:34:08.424944Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.404912Z"
    }
   },
   "source": [
    "## Classifier InceptionResidual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.427288Z",
     "iopub.status.busy": "2025-06-08T16:34:08.426721Z",
     "iopub.status.idle": "2025-06-08T16:34:08.443043Z",
     "shell.execute_reply": "2025-06-08T16:34:08.442385Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.427265Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class InceptionResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InceptionResidualBlock, self).__init__()\n",
    "        out_channel = int(out_channels//5)\n",
    "        \n",
    "        self.branch1x1 = nn.Conv2d(in_channels, out_channel, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch5x5_2 = nn.Conv2d(16, out_channel, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch3x3_2 = nn.Conv2d(16, out_channel, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = nn.Conv2d(in_channels, out_channel, kernel_size=1)\n",
    "\n",
    "        self.conv_residual = nn.Conv2d(in_channels, out_channel, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) < 3:\n",
    "            a, b = approximate_factors(x.shape[-1])\n",
    "            x = x.unsqueeze(1).view(x.shape[0], 1, a, b)\n",
    "            \n",
    "        identity = self.conv_residual(x)\n",
    "\n",
    "        branch1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1, branch5x5, branch3x3, branch_pool]\n",
    "        out = torch.cat(outputs, 1)\n",
    "\n",
    "        out = torch.cat((identity, out), dim=1)\n",
    "\n",
    "        return F.relu(out)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, batch_size=64, hidden_dim=512, num_layers=4, nheads=8, num_classes=41, dropout_rate=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim * 8\n",
    "\n",
    "        self.inception_res_block1 = InceptionResidualBlock(1, 80) \n",
    "        self.inception_res_block2 = InceptionResidualBlock(80, 125)\n",
    "        self.inception_res_block3 = InceptionResidualBlock(125, 250)\n",
    "        self.inception_res_block4 = InceptionResidualBlock(250, 500)\n",
    "        self.inception_res_block5 = InceptionResidualBlock(500, 750)\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim * 750, hidden_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, nhead=nheads, dim_feedforward=hidden_dim * 4, dropout=dropout_rate\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.inception_res_block1(x)\n",
    "        x = self.inception_res_block2(x)\n",
    "        x = self.inception_res_block3(x)\n",
    "        x = self.inception_res_block4(x)\n",
    "        x = self.inception_res_block5(x)\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "        x = x.squeeze(0) \n",
    "\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc_out(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier InceptionResidual Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.443899Z",
     "iopub.status.busy": "2025-06-08T16:34:08.443678Z",
     "iopub.status.idle": "2025-06-08T16:34:08.458097Z",
     "shell.execute_reply": "2025-06-08T16:34:08.457555Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.443883Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class InceptionResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InceptionResidualBlock, self).__init__()\n",
    "        out_channel = int(out_channels//5)\n",
    "        \n",
    "        self.branch1x1 = nn.Conv2d(in_channels, out_channel, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch5x5_2 = nn.Conv2d(16, out_channel, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch3x3_2 = nn.Conv2d(16, out_channel, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = nn.Conv2d(in_channels, out_channel, kernel_size=1)\n",
    "\n",
    "        self.conv_residual = nn.Conv2d(in_channels, out_channel, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) < 3:\n",
    "            a, b = approximate_factors(x.shape[-1])\n",
    "            x = x.unsqueeze(1).view(x.shape[0], 1, a, b)\n",
    "            \n",
    "        identity = self.conv_residual(x)\n",
    "\n",
    "        branch1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1, branch5x5, branch3x3, branch_pool]\n",
    "        out = torch.cat(outputs, 1)\n",
    "\n",
    "        out = torch.cat((identity, out), dim=1)\n",
    "\n",
    "        return F.relu(out)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, batch_size=64, hidden_dim=512, num_layers=4, nheads=8, num_classes=41, dropout_rate=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.model_extractor = AutoModelForAudioClassification.from_pretrained(\"bookbot/distil-ast-audioset\") \n",
    "        input_dim = 527\n",
    "        self.hidden_dim = hidden_dim * 8\n",
    "\n",
    "        self.inception_res_block1 = InceptionResidualBlock(1, 80) \n",
    "        self.inception_res_block2 = InceptionResidualBlock(80, 125)\n",
    "        self.inception_res_block3 = InceptionResidualBlock(125, 250)\n",
    "        self.inception_res_block4 = InceptionResidualBlock(250, 500)\n",
    "        self.inception_res_block5 = InceptionResidualBlock(500, 750)\n",
    "\n",
    "        self.fc1 = nn.Linear(527 * 750, hidden_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, nhead=nheads, dim_feedforward=hidden_dim * 4, dropout=dropout_rate\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.size(0)\n",
    "        x = self.model_extractor(x.reshape(x.size(0), 1024, 128))['logits']\n",
    "        x = self.inception_res_block1(x) \n",
    "        x = self.inception_res_block2(x)\n",
    "        x = self.inception_res_block3(x)\n",
    "        x = self.inception_res_block4(x)\n",
    "        x = self.inception_res_block5(x)\n",
    "        x = x.view(batch, 750*527)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.unsqueeze(0) \n",
    "        x = self.transformer(x)\n",
    "        x = x.squeeze(0) \n",
    "\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc_out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier InceptionResidual Large Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.459126Z",
     "iopub.status.busy": "2025-06-08T16:34:08.458877Z",
     "iopub.status.idle": "2025-06-08T16:34:08.478134Z",
     "shell.execute_reply": "2025-06-08T16:34:08.477442Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.459107Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class InceptionResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InceptionResidualBlock, self).__init__()\n",
    "        out_channel = int(out_channels//5)\n",
    "        \n",
    "        self.branch1x1 = nn.Conv2d(in_channels, out_channel, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch5x5_2 = nn.Conv2d(16, out_channel, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch3x3_2 = nn.Conv2d(16, out_channel, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = nn.Conv2d(in_channels, out_channel, kernel_size=1)\n",
    "\n",
    "        self.conv_residual = nn.Conv2d(in_channels, out_channel, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) < 3:\n",
    "            a, b = approximate_factors(x.shape[-1])\n",
    "            x = x.unsqueeze(1).view(x.shape[0], 1, a, b)\n",
    "            \n",
    "        identity = self.conv_residual(x)\n",
    "\n",
    "        branch1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1, branch5x5, branch3x3, branch_pool]\n",
    "        out = torch.cat(outputs, 1)\n",
    "\n",
    "        out = torch.cat((identity, out), dim=1)\n",
    "\n",
    "        return F.relu(out)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, batch_size=64, hidden_dim=512, num_layers=4, nheads=8, num_classes=41, dropout_rate=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.model_extractor = ASTModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "        input_dim = 768\n",
    "        self.hidden_dim = hidden_dim * 8\n",
    "\n",
    "        self.inception_res_block1 = InceptionResidualBlock(1, 80) \n",
    "        self.inception_res_block2 = InceptionResidualBlock(80, 125)\n",
    "        self.inception_res_block3 = InceptionResidualBlock(125, 250)\n",
    "        self.inception_res_block4 = InceptionResidualBlock(250, 500)\n",
    "        self.inception_res_block5 = InceptionResidualBlock(500, 750)\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim * 750, hidden_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, nhead=nheads, dim_feedforward=hidden_dim * 4, dropout=dropout_rate\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.size(0)\n",
    "        x = self.model_extractor(x.reshape(batch, 1024, 128))['pooler_output']\n",
    "        x = self.inception_res_block1(x) \n",
    "        x = self.inception_res_block2(x)\n",
    "        x = self.inception_res_block3(x)\n",
    "        x = self.inception_res_block4(x)\n",
    "        x = self.inception_res_block5(x)\n",
    "        x = x.view(batch, 750*768)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.unsqueeze(0)  \n",
    "\n",
    "        x = self.transformer(x)\n",
    "        x = x.squeeze(0)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc_out(x) \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier InceptionResidual3 Large Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.479053Z",
     "iopub.status.busy": "2025-06-08T16:34:08.478853Z",
     "iopub.status.idle": "2025-06-08T16:34:08.497276Z",
     "shell.execute_reply": "2025-06-08T16:34:08.496666Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.479038Z"
    }
   },
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class InceptionResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InceptionResidualBlock, self).__init__()\n",
    "        out_channel = int(out_channels // 4)\n",
    "\n",
    "        self.branch1x1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channel, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.branch5x5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channel, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.branch3x3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, out_channel, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.residual_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.se = SEBlock(out_channels)\n",
    "        self.final_bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.residual_conv(x)\n",
    "\n",
    "        out = torch.cat([\n",
    "            self.branch1x1(x),\n",
    "            self.branch5x5(x),\n",
    "            self.branch3x3(x),\n",
    "            self.branch_pool(x)\n",
    "        ], 1)\n",
    "\n",
    "        out += identity\n",
    "        out = self.se(out)\n",
    "        out = self.final_bn(out)\n",
    "        return self.relu(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.498179Z",
     "iopub.status.busy": "2025-06-08T16:34:08.497934Z",
     "iopub.status.idle": "2025-06-08T16:34:08.517233Z",
     "shell.execute_reply": "2025-06-08T16:34:08.516662Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.498154Z"
    }
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=41, dropout_rate=0.4):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.model_extractor = ASTModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "        self.cnn_input_dim = 768  # AST feature dimension\n",
    "\n",
    "        self.inception_blocks = nn.Sequential(\n",
    "            InceptionResidualBlock(1, 128),\n",
    "            InceptionResidualBlock(128, 256),\n",
    "            InceptionResidualBlock(256, 512),\n",
    "            InceptionResidualBlock(512, 768)\n",
    "        )\n",
    "\n",
    "        self.feature_reduce = nn.Conv2d(768, 256, kernel_size=1)\n",
    "        self.norm = nn.LayerNorm(196608)\n",
    "        self.fc1 = nn.Linear(196608, 512)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=512, nhead=8, dim_feedforward=2048, dropout=dropout_rate\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=12)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc_out = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.size(0)\n",
    "        x = self.model_extractor(x.view(batch, 1024, 128))['pooler_output'] \n",
    "\n",
    "        x = x.view(batch, 1, 24, 32) \n",
    "        x = self.inception_blocks(x)\n",
    "\n",
    "        x = self.feature_reduce(x) \n",
    "        x = x.flatten(start_dim=1)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = F.relu(self.fc1(x)).unsqueeze(0)\n",
    "\n",
    "        x = self.transformer(x).squeeze(0)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc_out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T16:34:08.517950Z",
     "iopub.status.busy": "2025-06-08T16:34:08.517765Z",
     "iopub.status.idle": "2025-06-08T16:34:23.171038Z",
     "shell.execute_reply": "2025-06-08T16:34:23.170427Z",
     "shell.execute_reply.started": "2025-06-08T16:34:08.517935Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model_register()\n",
    "model.batch_size = 10\n",
    "model.gen_datasets(train_features, test_features, 'spectr')\n",
    "model.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-08T15:57:58.687Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model_register()\n",
    "model.gen_datasets(train_features, test_features, 'spectr')\n",
    "model.get_model()\n",
    "model.train(epochs=15)\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model.model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-08T15:57:58.688Z"
    }
   },
   "outputs": [],
   "source": [
    "subm = pd.read_csv('/kaggle/input/lw1-acc/sample_submission.csv')\n",
    "subm['way'] = '/kaggle/input/lw1-acc/audio_test/audio_test/test/' + subm['fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-08T15:57:58.688Z"
    }
   },
   "outputs": [],
   "source": [
    "subm['label_id'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-08T15:57:58.688Z"
    }
   },
   "outputs": [],
   "source": [
    "subm_test = get_features5(subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-08T15:57:58.688Z"
    }
   },
   "outputs": [],
   "source": [
    "subm_test['spectr'] = np.array([m[0] for m in subm_test['spectr']], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-08T15:57:58.688Z"
    }
   },
   "outputs": [],
   "source": [
    "# input\n",
    "# subm_test['spectr'] = np.array([[pad_sequence(m, 1025)] for m in subm_test['spectr']], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3\n",
    "# subm_test['spectr'] = np.array([m['input_values'] for m in subm_test['spectr']], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-08T15:57:58.689Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in tqdm(subm_test['spectr']):\n",
    "    with torch.no_grad():\n",
    "        i = torch.tensor(i, dtype=torch.float32).to(model.device)\n",
    "        i = i.unsqueeze(0).to(model.device)\n",
    "        out = model.model(i).to('cpu')\n",
    "    probabilities = torch.softmax(out[0], dim=0)\n",
    "    predicted_classes = torch.argmax(probabilities, dim=0)\n",
    "    pred.append(unique_labels[predicted_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-08T15:57:58.689Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'fname':subm['fname'].to_list(), 'label':pred}).to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6842961,
     "sourceId": 11798518,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
